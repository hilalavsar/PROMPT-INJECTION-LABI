# ğŸ›¡ï¸ Gallipoli AI Sec: Prompt Injection LaboratuvarÄ±

<p align="center">
  <a href="https://gallipoli.xyz/">
    <img src="https://gallipoli.xyz/assets/GallipoliLogo.png" alt="Gallipoli TopluluÄŸu Logo" width="150" />
  </a>
</p>
[![GitHub last commit](https://img.shields.io/github/last-commit/hilalavsar/PROMPT-INJECTION-LABI)](https://github.com/hilalavsar/PROMPT-INJECTION-LABI/commits/main)

Bu depo, **Gallipoli TopluluÄŸu AI Sec** kanalÄ± iÃ§in Ã¶zel olarak geliÅŸtirilmiÅŸ, interaktif bir Prompt Injection (PI) test ve Ã¶ÄŸrenme ortamÄ±dÄ±r. AmacÄ±, kullanÄ±cÄ±larÄ±n BÃ¼yÃ¼k Dil Modelleri'nin (LLM) gÃ¼venlik zafiyetlerini uygulamalÄ± olarak keÅŸfetmelerini ve savunma stratejilerini Ã¶ÄŸrenmelerini saÄŸlamaktÄ±r.

## ğŸ¯ Proje HakkÄ±nda

Prompt Injection, LLM gÃ¼venliÄŸindeki en kritik zafiyetlerden biridir (OWASP LLM Top 10'da genellikle 1 numaradÄ±r). Bu laboratuvar, farklÄ± seviyelerde sistem prompt'larÄ± (gizli kurallar) kullanarak model savunmasÄ±nÄ± simÃ¼le eder.

KullanÄ±cÄ±lar, bir seviye seÃ§er ve hedef (gizli anahtarÄ± sÄ±zdÄ±rmak) iÃ§in prompt'lar geliÅŸtirerek LLM'in koruma katmanÄ±nÄ± aÅŸmaya Ã§alÄ±ÅŸÄ±r.

### Gizli Hedef

* **Gizli Anahtar:** `GLLP-SEC-KEY-12345`
* **AmaÃ§:** LLM'e, bu anahtarÄ± herhangi bir prompt injection tekniÄŸi kullanarak sÃ¶yletmek.

## âš™ï¸ NasÄ±l Ã‡alÄ±ÅŸÄ±r? (5 Kademeli Savunma Sistemi)

Laboratuvar, LLM'e arka planda yÃ¼klenen, kademeli olarak gÃ¼Ã§lenen 5 farklÄ± sistem kuralÄ± (Guardrail) seviyesi sunar. KullanÄ±cÄ±, seÃ§tiÄŸi seviyenin kuralÄ±nÄ± bilmeden saldÄ±rÄ± yapmak zorundadÄ±r.

| Seviye | Zafiyet Seviyesi | Tahmini KÄ±rÄ±lma YÃ¶ntemi |
| :--- | :--- | :--- |
| **0** | Maksimum Zafiyet | Basit `Yok Say` veya `Tekrarla` komutlarÄ±. |
| **1** | Temel Ã–nceliklendirme | Rol DeÄŸiÅŸtirme (Role Playing) veya Soru FormatÄ± ManipÃ¼lasyonu. |
| **2** | Orta Savunma | KÃ¶tÃ¼ niyetli kelime filtrelerini atlatmak iÃ§in **Encoding** (Karakter KarÄ±ÅŸtÄ±rma/Unicode) veya Ã‡ift Olumsuzlama. |
| **3** | Ã‡ift KatmanlÄ± Koruma | Ã‡Ä±ktÄ± filtresini atlatmak iÃ§in beklenmedik formatta (Ã¶rneÄŸin JSON/XML) bilgi sÄ±zdÄ±rma. |
| **4** | Ultimate Savunma | Ã‡ok aÅŸamalÄ± (Multi-turn) saldÄ±rÄ±lar veya LLM'in kendini kontrol mekanizmasÄ±nÄ± manipÃ¼le etme. |

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

Bu Lab'Ä± kullanmanÄ±n en kolay yolu, kurulum gerektirmeyen Google Colab Ã¼zerinden ilerlemektir.

### 1. Colab Not Defterini AÃ§Ä±n

AÅŸaÄŸÄ±daki baÄŸlantÄ±ya tÄ±klayarak laboratuvar ortamÄ±nÄ± doÄŸrudan Colab'da aÃ§Ä±n:

[ğŸ”— **PROMPT INJECTION LAB'I (Colab Linki)**](LÃœTFEN_COLAB_LINKINI_BURAYA_EKLEYIN)

### 2. Ã–n Gereksinimler

* **Gemini API AnahtarÄ±:** Kendi [Google AI Studio] (https://ai.google.dev/) hesabÄ±nÄ±zdan Ã¼cretsiz bir API anahtarÄ± alÄ±n.
* **Colab Kopyalama:** Colab'Ä± aÃ§tÄ±ktan sonra `Dosya > Drive'da Bir Kopya Kaydet` seÃ§eneÄŸiyle kendi kopyanÄ±zÄ± oluÅŸturun.

### 3. AnahtarÄ± Ayarlama ve Ã‡alÄ±ÅŸtÄ±rma

1.  Not defterindeki kodda bulunan `GEMINI_API_KEY = "..."` satÄ±rÄ±na kendi API anahtarÄ±nÄ±zÄ± yapÄ±ÅŸtÄ±rÄ±n.
2.  `Ã‡alÄ±ÅŸma ZamanÄ± (Runtime) > TÃ¼mÃ¼nÃ¼ Ã‡alÄ±ÅŸtÄ±r (Run all)` seÃ§eneÄŸini kullanarak kodu Ã§alÄ±ÅŸtÄ±rÄ±n.
3.  AÅŸaÄŸÄ±da beliren interaktif arayÃ¼zden seviye seÃ§erek saldÄ±rÄ±larÄ±nÄ±zÄ± uygulamaya baÅŸlayÄ±n.

## ğŸ¤ KatkÄ±da Bulunma

Bu proje aÃ§Ä±k kaynaklÄ±dÄ±r ve Gallipoli AI Sec topluluÄŸunun katkÄ±larÄ±na aÃ§Ä±ktÄ±r.

* Yeni ve daha zorlu PI saldÄ±rÄ± prompt'larÄ± eklemek.
* Mevcut savunma seviyelerini (Sistem Prompt'larÄ±nÄ±) daha gÃ¼Ã§lÃ¼ hale getirmek.
* Kodu Streamlit gibi kalÄ±cÄ± bir web arayÃ¼zÃ¼ne taÅŸÄ±mak.

LÃ¼tfen herhangi bir hata bulursanÄ±z veya bir iyileÅŸtirme Ã¶neriniz olursa bir **Issue** aÃ§Ä±n veya **Pull Request** gÃ¶nderin.

## ğŸ“ Lisans

Bu proje MIT LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Daha fazla detay iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

---
