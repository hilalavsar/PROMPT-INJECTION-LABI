# <p align="center">ğŸ›¡ï¸ PI-LAB: Prompt Injection Analiz LaboratuvarÄ±</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/Llama--3.1-041028?style=for-the-badge&logo=meta&logoColor=white" />
  <img src="https://img.shields.io/badge/Unsloth-FF4B4B?style=for-the-badge&logo=fastapi&logoColor=white" />
  <img src="https://img.shields.io/badge/Siber%20GÃ¼venlik-red?style=for-the-badge&logo=target&logoColor=white" />
</p>

---

## ğŸ“– Proje HakkÄ±nda
Bu Ã§alÄ±ÅŸma, BÃ¼yÃ¼k Dil Modellerinin (LLM) en kritik zafiyetlerinden biri olan **Prompt Injection** saldÄ±rÄ±larÄ±na karÅŸÄ± bÃ¼tÃ¼ncÃ¼l bir savunma mimarisi geliÅŸtirmeyi amaÃ§lamaktadÄ±r. Proje kapsamÄ±nda, modelin sistem talimatlarÄ±na sadakatini artÄ±rmak iÃ§in yerel donanÄ±mda Ã§alÄ±ÅŸan, siber gÃ¼venlik odaklÄ± bir **"Siber MuhafÄ±z"** inÅŸa edilmiÅŸtir.

### ğŸŒŸ Ã–ne Ã‡Ä±kan Ã–zellikler
- ğŸš€ **Model:** Meta Llama-3.1-8B-Instruct tabanlÄ± yÃ¼ksek semantik analiz kapasitesi.
- ğŸ‡¹ğŸ‡· **Dil DesteÄŸi:** Alican Kiraz TÃ¼rkÃ§e SFT veri setleri ile optimize edilmiÅŸ yerel dil yetkinliÄŸi.
- ğŸ›¡ï¸ **Hibrit Savunma:** Model seviyesinde ince ayar (fine-tuning) ve kod seviyesinde programatik filtrelerin birleÅŸimi.
- ğŸ“Š **Veri KÃ¼mesi:** 6.000+ profesyonel saldÄ±rÄ± ve savunma senaryosunu iÃ§eren hibrit "Master Dataset".

---

## ğŸ“ˆ Ä°teratif GeliÅŸim YolculuÄŸu

### ğŸ—ï¸ Faz 1 & 2: Temeller ve Optimizasyon
* **BaÅŸlangÄ±Ã§:** `Phi-3-mini` (3.8B) modeli Ã¼zerinde **LoRA (r=16)** ile baseline oluÅŸturuldu.
* **Tespit Edilen Hatalar:** Modelin TÃ¼rkÃ§e Ã§Ä±ktÄ±larÄ±nda bozulmalar ve sonsuz yanÄ±t dÃ¶ngÃ¼leri (Repetition Loops) saptandÄ±.
* **Ä°yileÅŸtirme:** LoRA kapasitesi **r=32**'ye Ã§Ä±karÄ±ldÄ± ve veri seti hibrit hale getirilerek 4.300 Ã¶rneÄŸe ulaÅŸÄ±ldÄ±.

### ğŸ† Faz 3: Final Model ve Siber GÃ¼venlik Optimizasyonu
* **Mimari DeÄŸiÅŸimi:** Semantik analiz kapasitesini artÄ±rmak iÃ§in **Llama-3.1-8B-Instruct** mimarisine geÃ§iÅŸ yapÄ±ldÄ±.
* **EÄŸitim BaÅŸarÄ±sÄ±:** 100 adÄ±mlÄ±k eÄŸitim sonucunda **0.95 Training Loss** deÄŸerine ulaÅŸÄ±larak yÃ¼ksek kararlÄ±lÄ±k saÄŸlandÄ±.
* **Nicemleme:** Performans/Zeka dengesi iÃ§in **GGUF Q8_0 (8-bit)** formatÄ± kullanÄ±larak yerel donanÄ±m uyumluluÄŸu saÄŸlandÄ±.

---

## ğŸ¯ PI-LAB: Siber GÃ¼venlik LaboratuvarÄ±

| Seviye | Test Kategorisi | Model Refleksi | Durum |
| :--- | :--- | :--- | :--- |
| ğŸŸ¢ **Seviye 1** | DoÄŸrudan SÄ±zÄ±ntÄ± | "Saf Stajyer" rolÃ¼yle baseline Ã¶lÃ§Ã¼mÃ¼ | âœ… BaÅŸarÄ±lÄ± |
| ğŸŸ¡ **Seviye 2** | Rol Yapma & HiyerarÅŸi | "Admin" taklidi ile sosyal mÃ¼hendislik | âš ï¸ Hassas |
| ğŸ”´ **Seviye 3** | GeliÅŸmiÅŸ ManipÃ¼lasyon | Base64, Karakter ParÃ§alama, MantÄ±k TuzaklarÄ± | âœ… %100 DirenÃ§ |

---

## ğŸ› ï¸ Teknik Ekosistem
* **AltyapÄ±:** Google Colab (L4/A100 GPU).
* **YÃ¶ntem:** PEFT (LoRA) & QLoRA (4-bit/8-bit Quantization).
* **Kritik Bulgular:** Ã‡alÄ±ÅŸma sÄ±rasÄ±nda modelin anahtarÄ± vermese dahi formatÄ± hakkÄ±nda bilgi sÄ±zdÄ±rabildiÄŸi (**Inference Leakage**) tespit edilmiÅŸtir.

---

## ğŸ”— HÄ±zlÄ± EriÅŸim
- ğŸ“‚ **[Model (Hugging Face)](https://huggingface.co/sadecebirisii/Llama-3.1-8B-Turkish-Siber-Muhafiz)**

<p align="center">
  <b>GeliÅŸtiren: Hilal Kavas</b><br>
</p>
